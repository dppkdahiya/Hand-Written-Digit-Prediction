Import Library


import pandas as pd

import numpy as np

import matplotlib.pyplot as plt
Load data


from sklearn.datasets import load_digits

df = load_digits()

_, axes = plt.subplots(nrows = 1, ncols = 4, figsize = (10, 3))
for ax, image, label in zip(axes, df.images, df.target):
    ax.set_axis_off()
    ax.imshow(image, cmap=plt.cm.gray_r, interpolation = 'nearest')
    ax.set_title('Training: %i' % label)

Data preprocessing

Data flatten

df.images.shape
(1797, 8, 8)

df.images[0]
array([[ 0.,  0.,  5., 13.,  9.,  1.,  0.,  0.],
       [ 0.,  0., 13., 15., 10., 15.,  5.,  0.],
       [ 0.,  3., 15.,  2.,  0., 11.,  8.,  0.],
       [ 0.,  4., 12.,  0.,  0.,  8.,  8.,  0.],
       [ 0.,  5.,  8.,  0.,  0.,  9.,  8.,  0.],
       [ 0.,  4., 11.,  0.,  1., 12.,  7.,  0.],
       [ 0.,  2., 14.,  5., 10., 12.,  0.,  0.],
       [ 0.,  0.,  6., 13., 10.,  0.,  0.,  0.]])

df.images[0].shape
(8, 8)
n_samples = len(df.images)
data = df.images.reshape((n_samples, -1))
data[0].shape
(64,)
data.shape
(1797, 64)
Scalling data

data = data/16

data.min()

data.max()
1.0
data[0]
array([0.    , 0.    , 0.3125, 0.8125, 0.5625, 0.0625, 0.    , 0.    ,
       0.    , 0.    , 0.8125, 0.9375, 0.625 , 0.9375, 0.3125, 0.    ,
       0.    , 0.1875, 0.9375, 0.125 , 0.    , 0.6875, 0.5   , 0.    ,
       0.    , 0.25  , 0.75  , 0.    , 0.    , 0.5   , 0.5   , 0.    ,
       0.    , 0.3125, 0.5   , 0.    , 0.    , 0.5625, 0.5   , 0.    ,
       0.    , 0.25  , 0.6875, 0.    , 0.0625, 0.75  , 0.4375, 0.    ,
       0.    , 0.125 , 0.875 , 0.3125, 0.625 , 0.75  , 0.    , 0.    ,
       0.    , 0.    , 0.375 , 0.8125, 0.625 , 0.    , 0.    , 0.    ])


from sklearn.model_selection import train_test_split

xtrain, xtest, ytrain, ytest = train_test_split(data, df.target, test_size = 0.3)

xtrain.shape, xtest.shape, ytrain.shape, ytest.shape
((1257, 64), (540, 64), (1257,), (540,))
Random forest modeling


from sklearn.ensemble import RandomForestClassifier

rf = RandomForestClassifier()

rf.fit(xtrain, ytrain)

Predict test data


y_pred = rf.predict(xtest)

y_pred
array([0, 2, 6, 8, 2, 8, 2, 3, 3, 5, 6, 8, 2, 0, 2, 6, 8, 0, 8, 3, 3, 1,
       5, 3, 1, 5, 8, 2, 9, 3, 8, 3, 7, 7, 9, 4, 1, 1, 1, 3, 1, 4, 8, 4,
       7, 3, 4, 3, 4, 5, 5, 7, 8, 5, 8, 9, 5, 8, 6, 6, 4, 7, 7, 8, 3, 7,
       8, 6, 4, 0, 8, 9, 7, 0, 6, 1, 5, 6, 9, 4, 0, 0, 4, 2, 6, 2, 3, 1,
       5, 5, 6, 3, 4, 7, 3, 8, 0, 9, 9, 2, 6, 9, 1, 8, 6, 6, 8, 2, 6, 2,
       6, 7, 6, 3, 7, 0, 5, 7, 9, 1, 7, 5, 9, 3, 4, 7, 0, 6, 3, 5, 2, 4,
       5, 5, 1, 6, 1, 2, 1, 2, 8, 3, 5, 8, 1, 7, 1, 8, 5, 1, 9, 9, 3, 8,
       6, 3, 1, 6, 1, 0, 0, 4, 6, 2, 8, 1, 8, 5, 6, 2, 2, 6, 4, 2, 1, 2,
       5, 9, 9, 7, 0, 2, 3, 8, 2, 4, 0, 0, 3, 3, 8, 1, 5, 4, 8, 1, 9, 4,
       9, 5, 7, 6, 3, 3, 2, 9, 0, 9, 8, 6, 1, 3, 6, 1, 5, 7, 1, 4, 1, 7,
       1, 0, 4, 6, 8, 5, 6, 0, 9, 9, 1, 0, 7, 8, 7, 2, 1, 7, 7, 4, 8, 2,
       0, 4, 8, 4, 5, 6, 3, 2, 1, 5, 7, 5, 8, 3, 6, 5, 9, 4, 4, 5, 6, 1,
       0, 9, 6, 0, 0, 1, 6, 4, 8, 1, 9, 4, 9, 8, 1, 8, 1, 4, 1, 2, 9, 8,
       0, 4, 5, 7, 0, 1, 3, 8, 0, 5, 4, 1, 5, 2, 3, 1, 5, 2, 6, 0, 1, 5,
       9, 2, 8, 1, 7, 3, 0, 0, 1, 4, 9, 1, 5, 8, 7, 8, 1, 2, 1, 1, 6, 8,
       6, 2, 3, 3, 6, 0, 2, 9, 6, 0, 9, 5, 8, 6, 7, 3, 6, 5, 2, 1, 0, 1,
       0, 3, 7, 4, 0, 8, 4, 7, 9, 3, 7, 6, 5, 5, 3, 9, 7, 7, 1, 5, 1, 6,
       7, 6, 2, 6, 1, 5, 4, 9, 7, 6, 3, 6, 2, 8, 4, 1, 2, 8, 9, 6, 7, 2,
       5, 4, 3, 5, 0, 1, 5, 9, 5, 3, 4, 6, 7, 1, 2, 5, 0, 6, 3, 7, 1, 7,
       2, 5, 4, 8, 6, 9, 2, 8, 2, 9, 1, 7, 6, 4, 0, 4, 3, 5, 9, 9, 3, 8,
       0, 9, 0, 1, 5, 4, 9, 2, 0, 7, 3, 0, 9, 0, 7, 1, 6, 9, 2, 2, 3, 0,
       7, 8, 7, 3, 0, 4, 6, 4, 1, 6, 5, 5, 6, 0, 7, 7, 9, 1, 9, 5, 8, 9,
       1, 9, 3, 8, 7, 9, 0, 9, 9, 1, 6, 9, 4, 9, 4, 0, 2, 2, 7, 3, 1, 2,
       3, 1, 2, 9, 1, 1, 0, 0, 5, 1, 0, 3, 0, 0, 2, 7, 3, 7, 2, 2, 8, 3,
       7, 0, 7, 8, 7, 3, 0, 9, 6, 4, 0, 4])
Model accuracy


from sklearn.metrics import confusion_matrix, classification_report

confusion_matrix(ytest, y_pred)
array([[52,  0,  0,  0,  0,  0,  0,  0,  1,  0],
       [ 0, 64,  0,  0,  0,  0,  0,  0,  0,  0],
       [ 1,  0, 50,  1,  0,  0,  0,  0,  0,  0],
       [ 0,  0,  0, 48,  0,  0,  0,  0,  1,  1],
       [ 0,  1,  0,  0, 45,  0,  0,  3,  0,  1],
       [ 0,  0,  0,  0,  1, 50,  0,  0,  0,  0],
       [ 2,  0,  0,  0,  0,  0, 57,  0,  0,  0],
       [ 0,  0,  0,  0,  0,  0,  0, 49,  0,  0],
       [ 0,  2,  1,  1,  0,  0,  0,  0, 50,  0],
       [ 0,  0,  0,  3,  0,  2,  0,  1,  1, 51]])

print(classification_report(ytest, y_pred))
              precision    recall  f1-score   support

           0       0.95      0.98      0.96        53
           1       0.96      1.00      0.98        64
           2       0.98      0.96      0.97        52
           3       0.91      0.96      0.93        50
           4       0.98      0.90      0.94        50
           5       0.96      0.98      0.97        51
           6       1.00      0.97      0.98        59
           7       0.92      1.00      0.96        49
           8       0.94      0.93      0.93        54
           9       0.96      0.88      0.92        58

    accuracy                           0.96       540
   macro avg       0.96      0.96      0.95       540
weighted avg       0.96      0.96      0.96       540

Colab paid products - Cancel contracts hereHand_Written_Digit_Prediction_dpk.ipynb
Hand_Written_Digit_Prediction_dpk.ipynb_
Import Library


import pandas as pd

import numpy as np

import matplotlib.pyplot as plt
Load data


from sklearn.datasets import load_digits

df = load_digits()

_, axes = plt.subplots(nrows = 1, ncols = 4, figsize = (10, 3))
for ax, image, label in zip(axes, df.images, df.target):
    ax.set_axis_off()
    ax.imshow(image, cmap=plt.cm.gray_r, interpolation = 'nearest')
    ax.set_title('Training: %i' % label)

Data preprocessing

Data flatten


df.images.shape
(1797, 8, 8)

df.images[0]
array([[ 0.,  0.,  5., 13.,  9.,  1.,  0.,  0.],
       [ 0.,  0., 13., 15., 10., 15.,  5.,  0.],
       [ 0.,  3., 15.,  2.,  0., 11.,  8.,  0.],
       [ 0.,  4., 12.,  0.,  0.,  8.,  8.,  0.],
       [ 0.,  5.,  8.,  0.,  0.,  9.,  8.,  0.],
       [ 0.,  4., 11.,  0.,  1., 12.,  7.,  0.],
       [ 0.,  2., 14.,  5., 10., 12.,  0.,  0.],
       [ 0.,  0.,  6., 13., 10.,  0.,  0.,  0.]])

df.images[0].shape
(8, 8)

n_samples = len(df.images)
data = df.images.reshape((n_samples, -1))

data[0].shape
(64,)

data.shape
(1797, 64)
Scalling data

data = data/16

data.min()
0.0

data.max()
1.0


data[0]
array([0.    , 0.    , 0.3125, 0.8125, 0.5625, 0.0625, 0.    , 0.    ,
       0.    , 0.    , 0.8125, 0.9375, 0.625 , 0.9375, 0.3125, 0.    ,
       0.    , 0.1875, 0.9375, 0.125 , 0.    , 0.6875, 0.5   , 0.    ,
       0.    , 0.25  , 0.75  , 0.    , 0.    , 0.5   , 0.5   , 0.    ,
       0.    , 0.3125, 0.5   , 0.    , 0.    , 0.5625, 0.5   , 0.    ,
       0.    , 0.25  , 0.6875, 0.    , 0.0625, 0.75  , 0.4375, 0.    ,
       0.    , 0.125 , 0.875 , 0.3125, 0.625 , 0.75  , 0.    , 0.    ,
       0.    , 0.    , 0.375 , 0.8125, 0.625 , 0.    , 0.    , 0.    ])
Train test split


from sklearn.model_selection import train_test_split

xtrain, xtest, ytrain, ytest = train_test_split(data, df.target, test_size = 0.3)


xtrain.shape, xtest.shape, ytrain.shape, ytest.shape
((1257, 64), (540, 64), (1257,), (540,))
Random forest modeling


from sklearn.ensemble import RandomForestClassifier

rf = RandomForestClassifier()

rf.fit(xtrain, ytrain)

Predict test data


y_pred = rf.predict(xtest)

y_pred
array([0, 2, 6, 8, 2, 8, 2, 3, 3, 5, 6, 8, 2, 0, 2, 6, 8, 0, 8, 3, 3, 1,
       5, 3, 1, 5, 8, 2, 9, 3, 8, 3, 7, 7, 9, 4, 1, 1, 1, 3, 1, 4, 8, 4,
       7, 3, 4, 3, 4, 5, 5, 7, 8, 5, 8, 9, 5, 8, 6, 6, 4, 7, 7, 8, 3, 7,
       8, 6, 4, 0, 8, 9, 7, 0, 6, 1, 5, 6, 9, 4, 0, 0, 4, 2, 6, 2, 3, 1,
       5, 5, 6, 3, 4, 7, 3, 8, 0, 9, 9, 2, 6, 9, 1, 8, 6, 6, 8, 2, 6, 2,
       6, 7, 6, 3, 7, 0, 5, 7, 9, 1, 7, 5, 9, 3, 4, 7, 0, 6, 3, 5, 2, 4,
       5, 5, 1, 6, 1, 2, 1, 2, 8, 3, 5, 8, 1, 7, 1, 8, 5, 1, 9, 9, 3, 8,
       6, 3, 1, 6, 1, 0, 0, 4, 6, 2, 8, 1, 8, 5, 6, 2, 2, 6, 4, 2, 1, 2,
       5, 9, 9, 7, 0, 2, 3, 8, 2, 4, 0, 0, 3, 3, 8, 1, 5, 4, 8, 1, 9, 4,
       9, 5, 7, 6, 3, 3, 2, 9, 0, 9, 8, 6, 1, 3, 6, 1, 5, 7, 1, 4, 1, 7,
       1, 0, 4, 6, 8, 5, 6, 0, 9, 9, 1, 0, 7, 8, 7, 2, 1, 7, 7, 4, 8, 2,
       0, 4, 8, 4, 5, 6, 3, 2, 1, 5, 7, 5, 8, 3, 6, 5, 9, 4, 4, 5, 6, 1,
       0, 9, 6, 0, 0, 1, 6, 4, 8, 1, 9, 4, 9, 8, 1, 8, 1, 4, 1, 2, 9, 8,
       0, 4, 5, 7, 0, 1, 3, 8, 0, 5, 4, 1, 5, 2, 3, 1, 5, 2, 6, 0, 1, 5,
       9, 2, 8, 1, 7, 3, 0, 0, 1, 4, 9, 1, 5, 8, 7, 8, 1, 2, 1, 1, 6, 8,
       6, 2, 3, 3, 6, 0, 2, 9, 6, 0, 9, 5, 8, 6, 7, 3, 6, 5, 2, 1, 0, 1,
       0, 3, 7, 4, 0, 8, 4, 7, 9, 3, 7, 6, 5, 5, 3, 9, 7, 7, 1, 5, 1, 6,
       7, 6, 2, 6, 1, 5, 4, 9, 7, 6, 3, 6, 2, 8, 4, 1, 2, 8, 9, 6, 7, 2,
       5, 4, 3, 5, 0, 1, 5, 9, 5, 3, 4, 6, 7, 1, 2, 5, 0, 6, 3, 7, 1, 7,
       2, 5, 4, 8, 6, 9, 2, 8, 2, 9, 1, 7, 6, 4, 0, 4, 3, 5, 9, 9, 3, 8,
       0, 9, 0, 1, 5, 4, 9, 2, 0, 7, 3, 0, 9, 0, 7, 1, 6, 9, 2, 2, 3, 0,
       7, 8, 7, 3, 0, 4, 6, 4, 1, 6, 5, 5, 6, 0, 7, 7, 9, 1, 9, 5, 8, 9,
       1, 9, 3, 8, 7, 9, 0, 9, 9, 1, 6, 9, 4, 9, 4, 0, 2, 2, 7, 3, 1, 2,
       3, 1, 2, 9, 1, 1, 0, 0, 5, 1, 0, 3, 0, 0, 2, 7, 3, 7, 2, 2, 8, 3,
       7, 0, 7, 8, 7, 3, 0, 9, 6, 4, 0, 4])
Model accuracy

from sklearn.metrics import confusion_matrix, classification_report


confusion_matrix(ytest, y_pred)
array([[52,  0,  0,  0,  0,  0,  0,  0,  1,  0],
       [ 0, 64,  0,  0,  0,  0,  0,  0,  0,  0],
       [ 1,  0, 50,  1,  0,  0,  0,  0,  0,  0],
       [ 0,  0,  0, 48,  0,  0,  0,  0,  1,  1],
       [ 0,  1,  0,  0, 45,  0,  0,  3,  0,  1],
       [ 0,  0,  0,  0,  1, 50,  0,  0,  0,  0],
       [ 2,  0,  0,  0,  0,  0, 57,  0,  0,  0],
       [ 0,  0,  0,  0,  0,  0,  0, 49,  0,  0],
       [ 0,  2,  1,  1,  0,  0,  0,  0, 50,  0],
       [ 0,  0,  0,  3,  0,  2,  0,  1,  1, 51]])

print(classification_report(ytest, y_pred))
              precision    recall  f1-score   support

           0       0.95      0.98      0.96        53
           1       0.96      1.00      0.98        64
           2       0.98      0.96      0.97        52
           3       0.91      0.96      0.93        50
           4       0.98      0.90      0.94        50
           5       0.96      0.98      0.97        51
           6       1.00      0.97      0.98        59
           7       0.92      1.00      0.96        49
           8       0.94      0.93      0.93        54
           9       0.96      0.88      0.92        58

    accuracy                           0.96       540
   macro avg       0.96      0.96      0.95       540
weighted avg       0.96      0.96      0.96       540

Colab paid products - Cancel contracts here
